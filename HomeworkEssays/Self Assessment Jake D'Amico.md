Jake D’Amico M13453113

**Self Assessment**

For our project I ended up taking the role as the primary software architect and developer for our project. The main things in our code base that I didn’t have a primary hand in writing were Zach’s Ridge Binary Classifier model as well as the styling of our front end, which was handled by Zach and Sean. I handled the architectural choices (mainly Flask + React), development of most of the backend to frontend data logic for our React components, and the Long Short Term Memory score prediction regression model. The main reason I made the choice of React and Flask was that I knew React would be a simple way to structure our web app which would be familiar enough that the team members could pick up on it easily without much experience, and Flask was picked because of both Python’s simplicity and the fact that we would be using Python for our machine learned models.

While this project topic probably wouldn’t have been my first choice personally, I ended up writing a lot of interesting code to solve some problems I had not faced. I think most of the interesting code had to do with my LSTM model and having it loaded into the backend to be queried. I actually was able to apply many concepts I had learned in my Deep Learning class that I am currently taking, including data prep concepts such as one-hot encoding, sequence padding, min-max feature scaling, and for the model itself, the LSTM architecture as well as dynamic batching. As web development is something I ended up loving from my co-op, my favorite parts of the implementation was how the model was actually connected to the front end. The model as well as the encoder from the one-hot encoding are first loaded into the flask server on startup so that it can be passed when front end functions are called. When a score prediction is requested, the backend would pass the play by play to the encoder so it can be one hot encoded in the same way that the training data was. The now encoded play by play could then be queried into the loaded PyTorch model, and the score was returned to the front end. To me at least, the process of loading a model in the backend and then querying it directly from the front end was a very interesting piece of code and something I was wondering for a while how it could be done.

I think our team was successful in many ways. Through the entire semester, we all really stuck to our roles and played them well, with Zach and I handling a bulk of the coding and Sean and Rylee handling a lot of the assignments as well as covering the styling of the pages, which I was definitely avoiding. We really were able to do a well designed multi page application in a rather short period of time, especially considering the work put into our ML models. Zach really did a great job with his binary classifier model based on rolling team data, and we thought it was cool having two separate models based on two separate features.

The main thing I learned from this experience was mainly about code base         organization and workflow. At times I definitely lost myself with code organization trying to rush to get features developed before the Expo, which was not something I had        experienced at my co-op being in intern type, low pressure development roles. I know my seniors have definitely experienced time crunches to get features developed and

had to make trade-offs, so it was interesting to also experience that to a degree. I also learned that using tools like GitHub as you develop and make changes is a large necessity as the project increases in size, as we had a few times where we wanted to revert but couldn’t because at the time we were not actively tracking changes on GitHub.

Overall, I really enjoyed the development of our final project and got to solve some problems I had never dealt with before, and am happy with the code I was able to output for this project.
